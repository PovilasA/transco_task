{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Jb9xiYDpXZlZaMB_7gnx7_Z0aFjjLkIb",
      "authorship_tag": "ABX9TyOp8r0amb59/1CuevTh3CTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PovilasA/transco_task/blob/main/Transco_task_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and loading libraries"
      ],
      "metadata": {
        "id": "9bskpxoi68zq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulAGKo3RQL8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1493ff-67db-4a36-fbba-1491d7527e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "HVLfSpzQULj1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiating/loading main objects"
      ],
      "metadata": {
        "id": "dS--2IjW7SSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key = userdata.get('openai_api_key'))\n",
        "audio_file_path = '/content/drive/MyDrive/Colab Notebooks/Transco task/aud-20240305025406001766-5f28b652ac8760c054204aa095bc31e3-C862.wav'"
      ],
      "metadata": {
        "id": "VRd91QwkQN_I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gpt4_call(prompt, temperature=1, max_tokens=256, top_p=1, frequency_penalty=0,  presence_penalty=0):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  return response"
      ],
      "metadata": {
        "id": "-X8oCzwB7sMh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting text from audio file using Whisper"
      ],
      "metadata": {
        "id": "YeTmLJG27kEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(audio_file_path, \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  prompt='File contains dialog between two people. Please output that as dialog for me to be able to understand who is saying what',\n",
        ")\n",
        "transcription_text = transcription.text\n",
        "print(transcription_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU1W-MESUCSZ",
        "outputId": "e5d9bf74-3b30-4f11-f0a4-52adbc744546"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey Fidel, I'm sorry, this is Juan. Hey, I'm done with the truck. Okay, perfect, perfect. What time is my truck going to kick in tomorrow? Let me see real quick. One second. For tomorrow it says open window actually. Let me double check that real quick, Fidel. I have an 8 a.m. appointment time for the delivery. On Wednesday? On Wednesday, yes sir. But it's a 24-7 facility, so if you have any trouble on the route, just give me a call so we can fix it, okay? Yeah, I'm not leaving until tomorrow. I'm out of time, so I just use PC out here? No, no, no, it's fine, it's fine. Are you at HQ, right? Yeah, I'm out of time, so... No, it's fine. You can sit down at headquarters. So I roll with YARMUV? Do I use YARMUV? Oh yeah, YARMUV, it's okay, it's fine. Okay, yeah, and you can also take the 15 minutes for the post-trip. It won't count like a violation, so you can take the 15 minutes for the post-trip. Oh, I can use it with the YARMUV? Yeah, yeah, yeah. Once you use the YARMUV and park, you can put yourself on non-duty for the post-trip. It is get out of YARMUV to on-duty? Exactly, yeah. Just before you end with the YARMUV, put yourself on duty, make the post-trip, and then sleep-prepared or off-duty. All right, sleep-prepared. Yeah. All right, then. All right, thank you. Okay, bye-bye. All right. Bye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text in more readable format:\n",
        "\n",
        "# text = \"\"\"\n",
        "# Hey, Fidel, I'm sorry, this is Juan. Hey, I'm done with the truck.\n",
        "# Okay, perfect, perfect. What time is my truck going to kick in tomorrow?\n",
        "# Let me see real quick. For tomorrow it says open window, actually.\n",
        "# Let me double check that real quick, Fidel.\n",
        "# I have an 8 a.m. appointment time for the delivery. On Wednesday?\n",
        "# On Wednesday, yes, sir. Alright. Yeah, yeah.\n",
        "# But it's a 24-7 facility, so if you have any trouble on the route, just give me a call so we can fix it, okay?\n",
        "# Yeah, I'm not leaving until tomorrow. I'm out of time, so I just use PC out here?\n",
        "# No, no, no, it's fine, it's fine. Are you at HQ, right? Yeah, I'm out of time, so...\n",
        "# No, it's fine, you can sit down at headquarters. So I roll with YARMUV?\n",
        "# Do I use YARMUV? Oh, yeah, YARMUV, it's okay, it's fine.\n",
        "# Okay, yeah, and you can also take the 15 minutes for the post-trip.\n",
        "# It won't count like a violation, so you can take the 15 minutes for the post-trip.\n",
        "# Oh, I can use it with the YARMUV? Yeah, yeah, yeah.\n",
        "# Once you use the YARMUV and park, you can put yourself on non-duty for the post-trip.\n",
        "# Post-trip? Yes, sir. It is get out of YARMUV to on-duty? Exactly, yeah.\n",
        "# Just before you end with the YARMUV, put yourself on duty, make the post-trip, and then sleep-prepared or off-duty.\n",
        "# All right, sleep-prepared. Yeah. All right, then. All right, thank you. Okay, bye-bye. All right. Bye.\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "vW1TMdur9xKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing text using GPT-4"
      ],
      "metadata": {
        "id": "1RAcw8i68Tkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialog between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please produce a concise summary (up to three sentences) encapsulating the essential points of the conversation?\n",
        "\"\"\"\n",
        "\n",
        "response1 = make_gpt4_call(prompt)\n",
        "print(response1.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z65gVtgXbJS",
        "outputId": "9e2cd44e-5805-4aea-afc9-9b0926a01dfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Juan informs Fidel that he has finished using the truck and discusses the appointment for delivery at 8 a.m. on Wednesday at a 24-7 facility. They discuss the logistic details concerning time management and the use of YARMUV for post-trip activities, with emphasis on adhering to non-violation regulations. Fidel assures Juan that using YARMUV is acceptable and advises him on how to log his post-trip time without violating any regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\"\"\"\n",
        "\n",
        "response2 = make_gpt4_call(prompt)\n",
        "print(response2.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HfKaJlu4XJ_",
        "outputId": "9cafd5b5-eaf1-4f69-bd8d-2050e794748c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The overall sentiment of the dialogue appears to be positive as both participants are cooperative, offering clarifications, solutions, and supportive responses throughout the conversation. The dialogue indicates a problem-solving situation where both parties are working towards a common goal without any sign of conflict or negativity. Considering these factors, I would rate the overall sentiment of the dialogue as 8/10. This reflects a high level of positivity, characterized by helpfulness and mutual understanding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract key emotions in the call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response3 = make_gpt4_call(prompt)\n",
        "print(response3.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j1Trlli4kzz",
        "outputId": "d6595681-6a3d-4d62-9e0d-b3ff6deedc79"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the dialogue between Fidel and Juan, here are the key emotions identified throughout the conversation, along with their scores:\n",
            "\n",
            "1. **Apology/Regret**: At the beginning of the call, Juan starts with \"I'm sorry, this is Juan.\" This shows a form of politeness or acknowledgment of a potential inconvenience. While it doesn't strongly suggest deep regret, it does carry a mild negative sentiment due to the apology. **Sentiment Score: 6**\n",
            "\n",
            "2. **Reassurance/Understanding**: Fidel's responses, such as \"Okay, perfect, perfect\" and detailed information about the appointment time, show a level of reassurance and understanding towards Juan's situation. It shifts the sentiment to a more positive note, indicating cooperation and support. **Sentiment Score: 8**\n",
            "\n",
            "3. **Concern/Worry**: The mention of \"it's a 24-7 facility, so if you have any trouble on the route, just give me a call\" displays a slight concern for potential issues but also readiness to assist. This duality carries a neutral-positive sentiment as it brings up potential worry but with a solution ready. **Sentiment Score: 7**\n",
            "\n",
            "4. **Anxiety/Relief Regarding Time Management**: Juan expressing \"I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract appointment time to aelivery from the dialogue?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response4 = make_gpt4_call(prompt)\n",
        "print(response4.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-NfWT5i4-tT",
        "outputId": "2e1e7c7c-69d6-4ed9-a7bd-9c720cfb1242"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appointment time for the delivery: 8 a.m. on Wednesday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final remarks/conclusions"
      ],
      "metadata": {
        "id": "T_oclvfu9m3y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhLnbKOL9qv_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}