{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Jb9xiYDpXZlZaMB_7gnx7_Z0aFjjLkIb",
      "authorship_tag": "ABX9TyPNvmvRcAsKYXpDT0A7JPDQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and loading libraries"
      ],
      "metadata": {
        "id": "9bskpxoi68zq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulAGKo3RQL8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6313f3e7-6120-4515-cd7e-18b6bb860ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "HVLfSpzQULj1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiating/loading main objects"
      ],
      "metadata": {
        "id": "dS--2IjW7SSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key = userdata.get('openai_api_key'))\n",
        "audio_file_path = '/content/drive/MyDrive/Colab Notebooks/Transco task/aud-20240305025406001766-5f28b652ac8760c054204aa095bc31e3-C862.wav'"
      ],
      "metadata": {
        "id": "VRd91QwkQN_I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gpt4_call(prompt, temperature=1, max_tokens=256, top_p=1, frequency_penalty=0,  presence_penalty=0):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  return response"
      ],
      "metadata": {
        "id": "-X8oCzwB7sMh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting text from audio file using Whisper"
      ],
      "metadata": {
        "id": "YeTmLJG27kEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(audio_file_path, \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  prompt='File contains dialogue between two people. Please output that as dialog for me to be able to understand who is saying what',\n",
        ")\n",
        "transcription_text = transcription.text\n",
        "print(transcription_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU1W-MESUCSZ",
        "outputId": "f9efca5e-9c25-4905-e1ec-d63d4d42b176"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is going on. I'm done with the truck. What time is my truck going to kick in tomorrow? Tomorrow it says open window. Let me double check that real quick. I have an 8 a.m. appointment time for the delivery. On Wednesday? Wednesday, yes sir. But it's a 24-7 facility, so if you have any trouble on the road, just give me a call so we can fix it, okay? I'm not leaving until tomorrow. I'm out of time, so I'll just use PC out here? No, no, it's fine. Are you at HQ, right? Yeah, I'm out of time. No, it's fine. You can sit down at the headquarters. Can I use YARMUV? Oh yeah, YARMUV is okay. You can also take the 15 minutes for the post-trip. It won't count like a violation, so you can take the 15 minutes for the post-trip. Oh, I can use it with YARMUV? Yeah, yeah, yeah. Once you use the YARMUV and park, you can put yourself on duty. Post-trip? Yes, sir. It is get out of YARMUV to on duty? Exactly, yeah. Just before you land with the YARMUV, put yourself on duty, make the post-trip, and then sleep or burst off or off duty. Alright, sleep or burst off. Yeah. Alright, then. Alright, thank you. Thank you. Bye-bye. Alright. Bye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text in more readable format:\n",
        "\n",
        "# text = \"\"\"\n",
        "# Hey, Fidel, I'm sorry, this is Juan. Hey, I'm done with the truck.\n",
        "# Okay, perfect, perfect. What time is my truck going to kick in tomorrow?\n",
        "# Let me see real quick. For tomorrow it says open window, actually.\n",
        "# Let me double check that real quick, Fidel.\n",
        "# I have an 8 a.m. appointment time for the delivery. On Wednesday?\n",
        "# On Wednesday, yes, sir. Alright. Yeah, yeah.\n",
        "# But it's a 24-7 facility, so if you have any trouble on the route, just give me a call so we can fix it, okay?\n",
        "# Yeah, I'm not leaving until tomorrow. I'm out of time, so I just use PC out here?\n",
        "# No, no, no, it's fine, it's fine. Are you at HQ, right? Yeah, I'm out of time, so...\n",
        "# No, it's fine, you can sit down at headquarters. So I roll with YARMUV?\n",
        "# Do I use YARMUV? Oh, yeah, YARMUV, it's okay, it's fine.\n",
        "# Okay, yeah, and you can also take the 15 minutes for the post-trip.\n",
        "# It won't count like a violation, so you can take the 15 minutes for the post-trip.\n",
        "# Oh, I can use it with the YARMUV? Yeah, yeah, yeah.\n",
        "# Once you use the YARMUV and park, you can put yourself on non-duty for the post-trip.\n",
        "# Post-trip? Yes, sir. It is get out of YARMUV to on-duty? Exactly, yeah.\n",
        "# Just before you end with the YARMUV, put yourself on duty, make the post-trip, and then sleep-prepared or off-duty.\n",
        "# All right, sleep-prepared. Yeah. All right, then. All right, thank you. Okay, bye-bye. All right. Bye.\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "vW1TMdur9xKs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing text using GPT-4"
      ],
      "metadata": {
        "id": "1RAcw8i68Tkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please produce a concise summary (up to three sentences) encapsulating the essential points of the conversation?\n",
        "\"\"\"\n",
        "\n",
        "response1 = make_gpt4_call(prompt)\n",
        "print(\"Task: Produce a concise summary encapsulating the essential points of the conversation.\")\n",
        "print(response1.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z65gVtgXbJS",
        "outputId": "cf58bf8b-ca4f-4ecf-8605-03acd1a3cd8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: Produce a concise summary encapsulating the essential points of the conversation.\n",
            "In the conversation, one person confirms their 8 a.m. delivery appointment for Wednesday at a 24-7 facility and discusses logistics about running out of driving time. They inquire about using personal conveyance (PC) and are advised they can rest at headquarters and use YARMUV without incurring a violation, followed by taking 15 minutes for a post-trip inspection before officially going off duty. They're instructed to switch from YARMUV to on-duty status just before completing the post-trip inspection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\"\"\"\n",
        "\n",
        "response2 = make_gpt4_call(prompt)\n",
        "print(\"Task: Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\")\n",
        "print(response2.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HfKaJlu4XJ_",
        "outputId": "8a916dca-cca2-4e22-bbf6-8e7b798a2eaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
            "Based on the text provided, the overall sentiment of the dialogue between the two people appears to be positive. Both parties are communicating effectively, solving a logistical issue with the truck delivery and scheduling. There's a tone of cooperation and helpfulness, with offers of support and solutions to potential problems. There is no apparent frustration, anger, or negative emotions conveyed in the exchange. Therefore, considering these aspects, I would rate the sentiment of the dialogue as an 8 on a scale from 1 to 10. This rating reflects a positive and constructive interaction, though not overly joyful or enthusiastic, which would be necessary to score it higher.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract key emotions in the call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response3 = make_gpt4_call(prompt)\n",
        "print(\"Task: Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\")\n",
        "print(response3.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j1Trlli4kzz",
        "outputId": "baaf3024-8dd4-42af-e2b4-3ba52b188450"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
            "Extracting key emotions from the given dialogue and assigning them scores based on sentiment can provide insights into the emotional tone of the conversation. Here's an analysis of the potential emotions and their scores:\n",
            "\n",
            "1. **Confusion/Inquiry** - The beginning of the dialogue starts with a character seeking clarification about the schedule, \"What time is my truck going to kick in tomorrow?\" This shows a level of uncertainty or confusion. The sentiment here isn't strongly negative or positive, so we might score this a **5**.\n",
            "\n",
            "2. **Reassurance** - When discussing the appointment and the nature of the 24-7 facility, there's a sense of reassurance provided, \"But it's a 24-7 facility, so if you have any trouble on the road, just give me a call so we can fix it, okay?\" This would likely invoke a positive sentiment for the person receiving the information, scored at **7**.\n",
            "\n",
            "3. **Concern/Worry** - The phrase, \"I'm not leaving until tomorrow. I'm out of time,\" indicates a concern or worry about the current situation, possibly related to hours of service regulations. The sentiment could be considered slightly negative due to stress or anxiety, scoring it a **4**.\n",
            "\n",
            "4. **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract appointment time to aelivery from the dialogue?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response4 = make_gpt4_call(prompt)\n",
        "print(\"Task: Extract Appointment time to Delivery from the dialogue.\")\n",
        "print(response4.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-NfWT5i4-tT",
        "outputId": "935b2094-6816-46ad-d79b-2dc7deda0110"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: Extract Appointment time to Delivery from the dialogue.\n",
            "Based on the dialogue provided, the appointment time for the delivery is at 8 a.m. on Wednesday.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final remarks/conclusions"
      ],
      "metadata": {
        "id": "T_oclvfu9m3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conclude I would like to add several remarks about the notebook.\n",
        "\n",
        "In general, I think that the main goals or questions specified in the task were answered here. I used the `whisper-1` model to get a transcript of the audio file. I am not giving any valuable information to the model about the audio file. I could have tried to do this but I think that we're looking for a general solution rather than analyzing this single conversation. Therefore, I only noticed that it is an audio dialogue of two people. Also, I did not give any information about the topic. Although maybe I could by saying that the topic is logistics or similar.\n",
        "\n",
        "When text is extracted I am using this as an input to the `gpt-4-turbo-preview` model. Prompt also contains questions that I would like to answer. Mostly I took the questions as it is except that in the first task I limited output to three sentences because initially the length of the call was almost the same as length of the summary.\n",
        "\n",
        "It is also worth mentioning that each call `gpt-4-turbo-preview` model is independent. It means that it does not have information about previous prompts. This could have been done in a chain but I decided that questions (and prompts) are not very dependent on each other so this solution is enough.\n",
        "\n",
        "To be honest, I am not sure if this solution is what was expected. However, I had very limited time for this so I simply made several API calls using `openai` library and that's it. I would be glad if you can share your feedback about what was done and what was expected.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IRgwDpdM-89n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhLnbKOL9qv_"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}