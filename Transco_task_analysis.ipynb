{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Jb9xiYDpXZlZaMB_7gnx7_Z0aFjjLkIb",
      "authorship_tag": "ABX9TyPL2S1+BJm81RS6yxNGYo4i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and loading libraries"
      ],
      "metadata": {
        "id": "9bskpxoi68zq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulAGKo3RQL8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9629ebeb-984b-422d-8c83-81478175e829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "HVLfSpzQULj1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiating/loading main objects"
      ],
      "metadata": {
        "id": "dS--2IjW7SSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key = userdata.get('openai_api_key'))\n",
        "audio_file_path = '/content/drive/MyDrive/Colab Notebooks/Transco task/aud-20240305025406001766-5f28b652ac8760c054204aa095bc31e3-C862.wav'"
      ],
      "metadata": {
        "id": "VRd91QwkQN_I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gpt4_call(prompt, temperature=1, max_tokens=256, top_p=1, frequency_penalty=0,  presence_penalty=0):\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "      }\n",
        "    ],\n",
        "    temperature=temperature,\n",
        "    max_tokens=max_tokens,\n",
        "    top_p=top_p,\n",
        "    frequency_penalty=frequency_penalty,\n",
        "    presence_penalty=presence_penalty\n",
        "  )\n",
        "  return response"
      ],
      "metadata": {
        "id": "-X8oCzwB7sMh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting text from audio file using Whisper"
      ],
      "metadata": {
        "id": "YeTmLJG27kEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file= open(audio_file_path, \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  prompt='File contains dialogue between two people. Please output that as dialog for me to be able to understand who is saying what',\n",
        ")\n",
        "transcription_text = transcription.text\n",
        "display(Markdown(f\"**Transcription text output**: \\n {transcription_text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "gU1W-MESUCSZ",
        "outputId": "25c60ba8-0532-4a1d-81b6-e0437362b5e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcription text output**: \n is going on. I'm done with the truck. What time is my truck going to kick in tomorrow? Tomorrow it says open window. Let me double check that real quick. I have an 8 a.m. appointment time for the delivery. On Wednesday? Wednesday, yes sir. But it's a 24-7 facility, so if you have any trouble on the road, just give me a call so we can fix it, okay? I'm not leaving until tomorrow. I'm out of time, so I'll just use PC out here? No, no, it's fine. Are you at HQ, right? Yeah, I'm out of time. No, it's fine. You can sit down at the headquarters. Can I use YARMUV? Oh yeah, YARMUV is okay. You can also take the 15 minutes for the post-trip. It won't count like a violation, so you can take the 15 minutes for the post-trip. Oh, I can use it with YARMUV? Yeah, yeah, yeah. Once you use the YARMUV and park, you can put yourself on duty. Post-trip? Yes, sir. It is get out of YARMUV to on duty? Exactly, yeah. Just before you land with the YARMUV, put yourself on duty, make the post-trip, and then sleep or burst off or off duty. Alright, sleep or burst off. Yeah. Alright, then. Alright, thank you. Thank you. Bye-bye. Alright. Bye."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text in more readable format (initial output):\n",
        "\n",
        "# text = \"\"\"\n",
        "# Hey, Fidel, I'm sorry, this is Juan. Hey, I'm done with the truck.\n",
        "# Okay, perfect, perfect. What time is my truck going to kick in tomorrow?\n",
        "# Let me see real quick. For tomorrow it says open window, actually.\n",
        "# Let me double check that real quick, Fidel.\n",
        "# I have an 8 a.m. appointment time for the delivery. On Wednesday?\n",
        "# On Wednesday, yes, sir. Alright. Yeah, yeah.\n",
        "# But it's a 24-7 facility, so if you have any trouble on the route, just give me a call so we can fix it, okay?\n",
        "# Yeah, I'm not leaving until tomorrow. I'm out of time, so I just use PC out here?\n",
        "# No, no, no, it's fine, it's fine. Are you at HQ, right? Yeah, I'm out of time, so...\n",
        "# No, it's fine, you can sit down at headquarters. So I roll with YARMUV?\n",
        "# Do I use YARMUV? Oh, yeah, YARMUV, it's okay, it's fine.\n",
        "# Okay, yeah, and you can also take the 15 minutes for the post-trip.\n",
        "# It won't count like a violation, so you can take the 15 minutes for the post-trip.\n",
        "# Oh, I can use it with the YARMUV? Yeah, yeah, yeah.\n",
        "# Once you use the YARMUV and park, you can put yourself on non-duty for the post-trip.\n",
        "# Post-trip? Yes, sir. It is get out of YARMUV to on-duty? Exactly, yeah.\n",
        "# Just before you end with the YARMUV, put yourself on duty, make the post-trip, and then sleep-prepared or off-duty.\n",
        "# All right, sleep-prepared. Yeah. All right, then. All right, thank you. Okay, bye-bye. All right. Bye.\n",
        "# \"\"\"\n"
      ],
      "metadata": {
        "id": "vW1TMdur9xKs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing text using GPT-4"
      ],
      "metadata": {
        "id": "1RAcw8i68Tkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please produce a concise summary (up to three sentences) encapsulating the essential points of the conversation?\n",
        "\"\"\"\n",
        "\n",
        "response1 = make_gpt4_call(prompt)\n",
        "\n",
        "display(Markdown(\"**Task:** Produce a concise summary encapsulating the essential points of the conversation. \\n\"))\n",
        "display(Markdown(f\"**Answer**: {response1.choices[0].message.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "-Z65gVtgXbJS",
        "outputId": "682e5373-4c64-489b-df28-6ef738ddb1f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Task:** Produce a concise summary encapsulating the essential points of the conversation. \n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer**: The dialogue involves two individuals discussing a truck delivery schedule, with a confirmed appointment at 8 a.m. on Wednesday at a 24-7 facility. They also discuss protocol for parking at headquarters using YARMUV, highlighting that a 15-minute post-trip does not count as a violation. Additionally, they cover the procedure for marking on-duty time after parking and before taking off-duty time for rest."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\"\"\"\n",
        "\n",
        "response2 = make_gpt4_call(prompt)\n",
        "\n",
        "display(Markdown(\"**Task:** Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment. \\n\"))\n",
        "display(Markdown(f\"**Answer**: {response2.choices[0].message.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "0HfKaJlu4XJ_",
        "outputId": "d14da1c0-aab3-4ea6-975c-a4b3e34d3869"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Task:** Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment. \n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer**: Based on the content of the dialogue, it appears to be a neutral to slightly positive interaction focused on logistical planning and clarifications concerning a truck delivery and related procedures. Both parties are cooperative, attempting to solve a logistical issue with no evident frustration or negativity. There's a tone of helpfulness and mutual understanding.\n\nGiven the context and the absence of strong negative or positive emotions, but considering the helpful and solution-oriented nature of the conversation, I would rate the overall sentiment of the dialogue as a 7 on a scale from 1 to 10. This rating reflects a slightly positive sentiment due to the helpful and cooperative exchange between the two individuals."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract key emotions in the call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response3 = make_gpt4_call(prompt)\n",
        "\n",
        "display(Markdown(\"**Task:** Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment. \\n\"))\n",
        "display(Markdown(f\"**Answer**: {response3.choices[0].message.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "8j1Trlli4kzz",
        "outputId": "bc71ed09-af3b-4274-e6a6-8dd1c2411f9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Task:** Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment. \n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer**: Certainly! Analyzing the dialogue for emotional undercurrents and their intensity involves interpreting the context, word choice, and the nature of the exchange. Below is an assessment of the key emotions present in the dialogue, with a scoring system as requested:\n\n1. **Confusion**: The dialogue begins with a certain level of confusion about the schedule and the processes to be followed. However, this confusion seems mild and is quickly addressed through clarification. **Score: 5**\n\n2. **Reassurance**: One of the speakers is reassuring the other regarding the process for managing the post-trip if they encounter any issues on the road. This sentiment is positive, as it conveys a sense of support and understanding. **Score: 8**\n\n3. **Concern**: There is a moment of concern when the speaker mentions being out of time and inquires about using PC outside. The concern reflects a worry about adherence to protocols or schedules. **Score: 4**\n\n4. **Cooperation**: The conversation has a cooperative tone, with both speakers working together to resolve the situation. This tone is prevalent throughout the dialogue and suggests a positive sentiment. **Score: 7**\n\n5. **Accommodation**: The allowance to use YARMUV and take 15 minutes for post"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Please take this text which is a dialogue between two people:\n",
        "\n",
        "{transcription_text}\n",
        "\n",
        "Can you please extract appointment time to delivery from the dialogue?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt\n",
        "\n",
        "response4 = make_gpt4_call(prompt)\n",
        "\n",
        "display(Markdown(\"**Task:** Extract Appointment time to Delivery from the dialogue. \\n\"))\n",
        "display(Markdown(f\"**Answer**: {response4.choices[0].message.content}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "g-NfWT5i4-tT",
        "outputId": "120e3e16-c72e-4b79-9d0a-d0f2c06f962f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Task:** Extract Appointment time to Delivery from the dialogue. \n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer**: The appointment time for the delivery mentioned in the dialogue is 8 a.m. on Wednesday."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final remarks/conclusions"
      ],
      "metadata": {
        "id": "T_oclvfu9m3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To conclude I would like to add several remarks about the notebook.\n",
        "\n",
        "In general, I think that the main goals or questions specified in the task were answered here. I used the `whisper-1` model to get a transcript of the audio file. I am not giving any valuable information to the model about the audio file. I could have tried to do this but I think that we're looking for a general solution rather than analyzing this single conversation. Therefore, I only noticed that it is an audio dialogue of two people. Also, I did not give any information about the topic. Although maybe I could by saying that the topic is logistics or similar.\n",
        "\n",
        "When text is extracted I am using this as an input to the `gpt-4-turbo-preview` model. Prompt also contains questions that I would like to answer. Mostly I took the questions as it is except that in the first task I limited output to three sentences because initially the length of the call was almost the same as length of the summary.\n",
        "\n",
        "It is also worth mentioning that each call to `gpt-4-turbo-preview` model is independent. It means that it does not have information about previous prompts. This could have been done in a chain but I decided that questions (and prompts) are not dependent on each other so this solution is enough.\n",
        "\n",
        "Another thing that could have been done here is trying to set the seed for reproducability. I've never tried this in `openai` API but I saw somewhere it is possible. For this reason the text `whisper-1` extracts is not exactly the same in different iterations.\n",
        "\n",
        "To be honest, I am not sure if this solution is what was expected. However, I had very limited time for this so I simply made several API calls using `openai` library and that's it. I would be glad if you can share your feedback about what was done and what was expected.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IRgwDpdM-89n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vhLnbKOL9qv_"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}